import logging
from aiogram import Bot, Dispatcher, types
import g4f
from aiogram.utils import executor

# –í–∫–ª—é—á–∏—Ç–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
API_TOKEN = '7260923111:AAHWVWgydzQ4BIP84i2mnCRQrqanOvGicHQ'
bot = Bot(token=API_TOKEN)
dp = Dispatcher(bot)

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤
conversation_history = {}

@dp.message_handler(commands=['start'])
async def welcome(message: types.Message):
    file = open('./Screenshot_1.png', 'rb')
    await bot.send_photo(message.chat.id, file, '<b>–ü—Ä–∏–≤–µ—Ç! –Ø Chat GPT</b>ü§ñ\n\n–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç <b>–¥—Ä—É–≥–∏—Ö</b>, —è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é <em>–±–µ–∑–ª–∏–º–∏—Ç–Ω—ã–π –¥–æ—Å—Ç—É–ø</em>, –∏ –≤–∞–º –Ω–µ –Ω—É–∂–Ω–æ –æ–ø–ª–∞—á–∏–≤–∞—Ç—å <em>–ø–æ–¥–ø–∏—Å–∫—É</em> –∏–ª–∏ –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å—Å—è –Ω–∞ –∫–∞–Ω–∞–ª—ã.\n–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ, —á—Ç–æ –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç, –∏ —è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–∞–º –æ—Ç–≤–µ—á—É.', parse_mode='html')

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–µ–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
def trim_history(history, max_length=4096):
    current_length = sum(len(message["content"]) for message in history)
    while history and current_length > max_length:
        removed_message = history.pop(0)
        current_length -= len(removed_message["content"])
    return history


@dp.message_handler(commands=['clear'])
async def process_clear_command(message: types.Message):
    user_id = message.from_user.id
    conversation_history[user_id] = []
    await message.reply("–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞.")

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
@dp.message_handler()
async def send_welcome(message: types.Message):
    user_id = message.from_user.id
    user_input = message.text

    wait = await bot.send_message(message.chat.id, '–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –∑–∞–ø—Ä–æ—Å‚è≥, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø–æ–¥–æ–∂–¥–∏—Ç–µ...')

    if user_id not in conversation_history:
        conversation_history[user_id] = []

    conversation_history[user_id].append({"role": "user", "content": user_input})
    conversation_history[user_id] = trim_history(conversation_history[user_id])

    chat_history = conversation_history[user_id]

    try:
        response = await g4f.ChatCompletion.create_async(
            model=g4f.models.default,
            messages=chat_history,
            provider=g4f.Provider.GeekGpt,
        )
        chat_gpt_response = response
    except Exception as e:
        print(f"{g4f.Provider.GeekGpt.__name__}:", e)
        chat_gpt_response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞."

    conversation_history[user_id].append({"role": "assistant", "content": chat_gpt_response})
    print(conversation_history)
    length = sum(len(message["content"]) for message in conversation_history[user_id])
    print(length)

    await message.answer(chat_gpt_response)
    await wait.delete()


# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == '__main__':
    executor.start_polling(dp, skip_updates=True)